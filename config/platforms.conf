# Platform Configuration for LLM Benchmarks
# This file defines the platforms to be benchmarked

[your_platform]
name = "Your Platform"
base_url = "${PLATFORM_API_BASE_URL}"
api_key = "${PLATFORM_API_KEY}"
models = [
    "openai/gpt-oss-120b"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[openrouter]
name = "OpenRouter"
base_url = "https://openrouter.ai/api/v1"
api_key = "${OPENROUTER_API_KEY}"
models = [
    "openai/gpt-4o",
    "anthropic/claude-3.5-sonnet",
    "meta-llama/llama-3.1-70b-instruct"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[openai]
name = "OpenAI"
base_url = "https://api.openai.com/v1"
api_key = "${OPENAI_API_KEY}"
models = [
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-3.5-turbo"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[anthropic]
name = "Anthropic"
base_url = "https://api.anthropic.com"
api_key = "${ANTHROPIC_API_KEY}"
models = [
    "claude-3-5-sonnet-20241022",
    "claude-3-haiku-20240307"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[azure_openai]
name = "Azure OpenAI"
base_url = "${AZURE_OPENAI_ENDPOINT}"
api_key = "${AZURE_OPENAI_API_KEY}"
models = [
    "gpt-4o",
    "gpt-4o-mini"
]
timeout = 60
max_retries = 3
retry_delay = 1.0
api_version = "2024-02-15-preview"

[google_gemini]
name = "Google Gemini"
base_url = "https://generativelanguage.googleapis.com/v1beta"
api_key = "${GOOGLE_GEMINI_API_KEY}"
models = [
    "gemini-1.5-pro",
    "gemini-1.5-flash"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[cohere]
name = "Cohere"
base_url = "https://api.cohere.ai/v1"
api_key = "${COHERE_API_KEY}"
models = [
    "command-r-plus",
    "command"
]
timeout = 60
max_retries = 3
retry_delay = 1.0

[replicate]
name = "Replicate"
base_url = "https://api.replicate.com/v1"
api_key = "${REPLICATE_API_KEY}"
models = [
    "meta/meta-llama-3.1-70b-instruct",
    "mistralai/mixtral-8x7b-instruct-v0.1"
]
timeout = 120
max_retries = 3
retry_delay = 2.0

[huggingface]
name = "Hugging Face"
base_url = "${HUGGINGFACE_ENDPOINT}"
api_key = "${HUGGINGFACE_API_KEY}"
models = [
    "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "meta-llama/Llama-2-70b-chat-hf"
]
timeout = 120
max_retries = 3
retry_delay = 2.0

[aws_bedrock]
name = "AWS Bedrock"
base_url = "${AWS_BEDROCK_ENDPOINT}"
api_key = "${AWS_BEDROCK_API_KEY}"  # Uses AWS credentials instead
models = [
    "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "meta.llama3-1-70b-instruct-v1:0"
]
timeout = 60
max_retries = 3
retry_delay = 1.0
region = "us-east-1"

[example_local]
name = "Local Server"
base_url = "http://localhost:8000/v1"
api_key = "sk-local-test-key"
models = [
    "llama-2-7b-chat",
    "mistral-7b-instruct"
]
timeout = 120
max_retries = 5
retry_delay = 2.0
validate_backend = false